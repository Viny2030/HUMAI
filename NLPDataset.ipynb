{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Viny2030/HUMAI/blob/main/NLPDataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construcción de un Dataset para Procesamiento de Lenguaje Natural\n",
        "\n",
        "En este notebook vamos a aprender a trabajar con texto para generar un dataset que nos permita entrenar modelos de Procesamiento de Lenguaje Natural. Para esto vamos a ver un ejemplo en una tarea particular, pero los conceptos necesarios para construir este dataset son aplicables a todas las tareas del rubro.  "
      ],
      "metadata": {
        "id": "48tIRcA70qrD"
      },
      "id": "48tIRcA70qrD"
    },
    {
      "cell_type": "markdown",
      "id": "60e23820",
      "metadata": {
        "origin_pos": 0,
        "id": "60e23820"
      },
      "source": [
        "## Inferencia del lenguaje natural\n",
        "\n",
        "La **Inferencia del lenguaje natural** estudia si una *hipótesis*\n",
        "se puede inferir de una *premisa*, donde ambas son una secuencia de texto.\n",
        "En otras palabras, la inferencia del lenguaje natural determina la relación lógica entre un par de secuencias de texto.\n",
        "Estas relaciones suelen clasificarse en tres tipos:\n",
        "\n",
        "* *Implicación* (entailment): la hipótesis se puede inferir de la premisa.\n",
        "* *Contradicción* (contradiction): la negación de la hipótesis se puede inferir de la premisa.\n",
        "* *Neutral*: todos los demás casos.\n",
        "\n",
        "La inferencia del lenguaje natural también se conoce como tarea de reconocimiento de vinculación textual.\n",
        "\n",
        "Por ejemplo, el siguiente par se etiquetará como *Implicación* porque  \"showing affection\" en la hipótesis se puede inferir de \"hugging one another\" en la premisa.\n",
        "\n",
        "> Premise: Two women are hugging each other.\n",
        "\n",
        "> Hypothesis: Two women are showing affection.\n",
        "\n",
        "El siguiente es un ejemplo de *contradicción* ya que \"running the coding example\" indica \"not sleeping\" en lugar de \"sleeping\".\n",
        "\n",
        "> Premise: A man is running the coding example from Dive into Deep Learning.\n",
        "\n",
        "> Hypothesis: The man is sleeping.\n",
        "\n",
        "El tercer ejemplo muestra una relación de *neutralidad* porque ni \"famous\" ni \"not famous\" pueden inferirse del hecho de que \"are performing for us\".\n",
        "\n",
        "> Premise: The musicians are performing for us.\n",
        "\n",
        "> Hypothesis: The musicians are famous.\n",
        "\n",
        "La inferencia del lenguaje natural ha sido un tema central para comprender el lenguaje natural. Disfruta de amplias aplicaciones que van desde la recuperación de información hasta la respuesta a preguntas de dominio abierto. Para estudiar este problema, comenzaremos investigando un conjunto de datos de referencia de inferencia de lenguaje natural popular.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Stanford Natural Language Inference (SNLI) Dataset\n",
        "\n",
        "El corpus de inferencia del lenguaje natural de Stanford (SNLI) es una colección de más de 500 000 pares de oraciones etiquetadas en inglés.\n",
        "Descargamos y almacenamos el conjunto de datos SNLI extraído en la ruta `../data/snli_1.0`."
      ],
      "metadata": {
        "id": "oroUdAYM3857"
      },
      "id": "oroUdAYM3857"
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install d2l==1.0.3"
      ],
      "metadata": {
        "id": "qFgoxJy03Lkx"
      },
      "id": "qFgoxJy03Lkx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20eadf89",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-13T08:04:24.710173Z",
          "iopub.status.busy": "2022-07-13T08:04:24.709583Z",
          "iopub.status.idle": "2022-07-13T08:04:32.102089Z",
          "shell.execute_reply": "2022-07-13T08:04:32.101192Z"
        },
        "origin_pos": 2,
        "tab": [
          "pytorch"
        ],
        "id": "20eadf89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbacffba-38cd-42b9-ff26-81d236fe0735"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ../data/snli_1.0.zip from https://nlp.stanford.edu/projects/snli/snli_1.0.zip...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l\n",
        "\n",
        "d2l.DATA_HUB['SNLI'] = (\n",
        "    'https://nlp.stanford.edu/projects/snli/snli_1.0.zip',\n",
        "    '9fcde07509c7e87ec61c640c1b2753d9041758e4')\n",
        "\n",
        "data_dir = d2l.download_extract('SNLI')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El dataset está estructurado como un archivo separado por tabs. Usaremos pandas para leerlo."
      ],
      "metadata": {
        "id": "ppXeS1FITe92"
      },
      "id": "ppXeS1FITe92"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(os.path.join(data_dir, 'snli_1.0_train.txt'), sep='\\t')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "SgnITMrIUdxP",
        "outputId": "6f3e4194-c5a5-49d6-8ed9-2df4d39f115c"
      },
      "id": "SgnITMrIUdxP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      gold_label                             sentence1_binary_parse  \\\n",
              "0        neutral  ( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...   \n",
              "1  contradiction  ( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...   \n",
              "2     entailment  ( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...   \n",
              "3        neutral  ( Children ( ( ( smiling and ) waving ) ( at c...   \n",
              "4     entailment  ( Children ( ( ( smiling and ) waving ) ( at c...   \n",
              "\n",
              "                              sentence2_binary_parse  \\\n",
              "0  ( ( A person ) ( ( is ( ( training ( his horse...   \n",
              "1  ( ( A person ) ( ( ( ( is ( at ( a diner ) ) )...   \n",
              "2  ( ( A person ) ( ( ( ( is outdoors ) , ) ( on ...   \n",
              "3  ( They ( are ( smiling ( at ( their parents ) ...   \n",
              "4             ( There ( ( are children ) present ) )   \n",
              "\n",
              "                                     sentence1_parse  \\\n",
              "0  (ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...   \n",
              "1  (ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...   \n",
              "2  (ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...   \n",
              "3  (ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...   \n",
              "4  (ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...   \n",
              "\n",
              "                                     sentence2_parse  \\\n",
              "0  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...   \n",
              "1  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...   \n",
              "2  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...   \n",
              "3  (ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...   \n",
              "4  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...   \n",
              "\n",
              "                                           sentence1  \\\n",
              "0  A person on a horse jumps over a broken down a...   \n",
              "1  A person on a horse jumps over a broken down a...   \n",
              "2  A person on a horse jumps over a broken down a...   \n",
              "3              Children smiling and waving at camera   \n",
              "4              Children smiling and waving at camera   \n",
              "\n",
              "                                           sentence2         captionID  \\\n",
              "0  A person is training his horse for a competition.  3416050480.jpg#4   \n",
              "1      A person is at a diner, ordering an omelette.  3416050480.jpg#4   \n",
              "2                  A person is outdoors, on a horse.  3416050480.jpg#4   \n",
              "3                  They are smiling at their parents  2267923837.jpg#2   \n",
              "4                         There are children present  2267923837.jpg#2   \n",
              "\n",
              "                pairID         label1 label2 label3 label4 label5  \n",
              "0  3416050480.jpg#4r1n        neutral    NaN    NaN    NaN    NaN  \n",
              "1  3416050480.jpg#4r1c  contradiction    NaN    NaN    NaN    NaN  \n",
              "2  3416050480.jpg#4r1e     entailment    NaN    NaN    NaN    NaN  \n",
              "3  2267923837.jpg#2r1n        neutral    NaN    NaN    NaN    NaN  \n",
              "4  2267923837.jpg#2r1e     entailment    NaN    NaN    NaN    NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-232d1575-25f4-4c00-8586-d5a0f9f3f422\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gold_label</th>\n",
              "      <th>sentence1_binary_parse</th>\n",
              "      <th>sentence2_binary_parse</th>\n",
              "      <th>sentence1_parse</th>\n",
              "      <th>sentence2_parse</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>captionID</th>\n",
              "      <th>pairID</th>\n",
              "      <th>label1</th>\n",
              "      <th>label2</th>\n",
              "      <th>label3</th>\n",
              "      <th>label4</th>\n",
              "      <th>label5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>( ( A person ) ( ( is ( ( training ( his horse...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>A person is training his horse for a competition.</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>3416050480.jpg#4r1n</td>\n",
              "      <td>neutral</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>contradiction</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>( ( A person ) ( ( ( ( is ( at ( a diner ) ) )...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>A person is at a diner, ordering an omelette.</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>3416050480.jpg#4r1c</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>entailment</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>( ( A person ) ( ( ( ( is outdoors ) , ) ( on ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>A person is outdoors, on a horse.</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>3416050480.jpg#4r1e</td>\n",
              "      <td>entailment</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neutral</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>( They ( are ( smiling ( at ( their parents ) ...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>(ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>They are smiling at their parents</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>2267923837.jpg#2r1n</td>\n",
              "      <td>neutral</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entailment</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>( There ( ( are children ) present ) )</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>There are children present</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>2267923837.jpg#2r1e</td>\n",
              "      <td>entailment</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-232d1575-25f4-4c00-8586-d5a0f9f3f422')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-232d1575-25f4-4c00-8586-d5a0f9f3f422 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-232d1575-25f4-4c00-8586-d5a0f9f3f422');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-120a6bbd-17d8-4914-ad4a-312aaaca8f10\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-120a6bbd-17d8-4914-ad4a-312aaaca8f10')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-120a6bbd-17d8-4914-ad4a-312aaaca8f10 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "983e9e6a",
      "metadata": {
        "origin_pos": 3,
        "id": "983e9e6a"
      },
      "source": [
        "### Leyendo el dataset\n",
        "\n",
        "El conjunto de datos SNLI original contiene información mucho más rica de la que realmente necesitamos en nuestros experimentos. Por lo tanto, definimos una función `read_snli` para extraer solo parte del conjunto de datos y luego devolver listas de premisas, hipótesis y sus etiquetas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b4c3ed1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-13T08:04:32.106656Z",
          "iopub.status.busy": "2022-07-13T08:04:32.105964Z",
          "iopub.status.idle": "2022-07-13T08:04:32.113805Z",
          "shell.execute_reply": "2022-07-13T08:04:32.112957Z"
        },
        "origin_pos": 4,
        "tab": [
          "pytorch"
        ],
        "id": "0b4c3ed1"
      },
      "outputs": [],
      "source": [
        "def read_snli(data_dir, is_train):\n",
        "    \"\"\"Read the SNLI dataset into premises, hypotheses, and labels.\"\"\"\n",
        "    def extract_text(s):\n",
        "        # Remove information that will not be used by us\n",
        "        s = re.sub('\\\\(', '', s)\n",
        "        s = re.sub('\\\\)', '', s)\n",
        "        # Substitute two or more consecutive whitespace with space\n",
        "        s = re.sub('\\\\s{2,}', ' ', s)\n",
        "        return s.strip()\n",
        "    label_set = {'entailment': 0, 'contradiction': 1, 'neutral': 2}\n",
        "    file_name = os.path.join(data_dir, 'snli_1.0_train.txt'\n",
        "                             if is_train else 'snli_1.0_test.txt')\n",
        "    with open(file_name, 'r') as f:\n",
        "        rows = [row.split('\\t') for row in f.readlines()[1:]]\n",
        "    premises = [extract_text(row[1]) for row in rows if row[0] in label_set]\n",
        "    hypotheses = [extract_text(row[2]) for row in rows if row[0] in label_set]\n",
        "    labels = [label_set[row[0]] for row in rows if row[0] in label_set]\n",
        "    return premises, hypotheses, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0967325",
      "metadata": {
        "origin_pos": 5,
        "id": "a0967325"
      },
      "source": [
        "Ahora imprimamos los primeros 3 pares de premisa e hipótesis, así como sus etiquetas (\"0\", \"1\" y \"2\" corresponden a \"entailment\", \"contradiction\" y \"neutral\", respectivamente).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a90edb4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-13T08:04:32.117404Z",
          "iopub.status.busy": "2022-07-13T08:04:32.116954Z",
          "iopub.status.idle": "2022-07-13T08:04:45.241110Z",
          "shell.execute_reply": "2022-07-13T08:04:45.239517Z"
        },
        "origin_pos": 6,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a90edb4",
        "outputId": "4d844427-2a5b-4f55-cd9d-ac345e887432"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "premise: A person on a horse jumps over a broken down airplane .\n",
            "hypothesis: A person is training his horse for a competition .\n",
            "label: 2\n",
            "premise: A person on a horse jumps over a broken down airplane .\n",
            "hypothesis: A person is at a diner , ordering an omelette .\n",
            "label: 1\n",
            "premise: A person on a horse jumps over a broken down airplane .\n",
            "hypothesis: A person is outdoors , on a horse .\n",
            "label: 0\n"
          ]
        }
      ],
      "source": [
        "train_data = read_snli(data_dir, is_train=True)\n",
        "for x0, x1, y in zip(train_data[0][:3], train_data[1][:3], train_data[2][:3]):\n",
        "    print('premise:', x0)\n",
        "    print('hypothesis:', x1)\n",
        "    print('label:', y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49655a12",
      "metadata": {
        "origin_pos": 7,
        "id": "49655a12"
      },
      "source": [
        "El conjunto de entrenamiento tiene alrededor de 550000 pares,\n",
        "y el conjunto de prueba tiene alrededor de 10000 pares.\n",
        "A continuación se muestra que\n",
        "las tres etiquetas están equilibradas en\n",
        "tanto el conjunto de entrenamiento como el de prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cb739ac",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-13T08:04:45.248922Z",
          "iopub.status.busy": "2022-07-13T08:04:45.247821Z",
          "iopub.status.idle": "2022-07-13T08:04:45.642873Z",
          "shell.execute_reply": "2022-07-13T08:04:45.641631Z"
        },
        "origin_pos": 8,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cb739ac",
        "outputId": "93e07455-75bc-478c-8ecc-54b81fa3864c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[183416, 183187, 182764]\n",
            "[3368, 3237, 3219]\n"
          ]
        }
      ],
      "source": [
        "test_data = read_snli(data_dir, is_train=False)\n",
        "for data in [train_data, test_data]:\n",
        "    print([[row for row in data[2]].count(i) for i in range(3)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenización con Spacy"
      ],
      "metadata": {
        "id": "XnWOhI8jm3rj"
      },
      "id": "XnWOhI8jm3rj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "La tokenización es la tarea de dividir un texto en segmentos significativos, llamados tokens. La entrada al tokenizador es un texto Unicode y la salida es un objeto Doc de Spacy.\n",
        "\n",
        "La tokenización de spaCy no es destructiva, lo que significa que siempre podrás reconstruir la entrada original a partir de la salida tokenizada. La información de los espacios en blanco se conserva en los tokens y no se agrega ni elimina ninguna información durante la tokenización. Este es una especie de principio básico del objeto Doc de spaCy: `doc.text == input_text` siempre debe ser verdadero.\n"
      ],
      "metadata": {
        "id": "6PdPQkTam68o"
      },
      "id": "6PdPQkTam68o"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Durante el procesamiento, spaCy primero tokeniza el texto, es decir, lo segmenta en palabras, signos de puntuación, etc. Esto se hace aplicando reglas específicas de cada idioma. Por ejemplo, la puntuación al final de una frase debe separarse, mientras que “EE.UU.” debería seguir siendo un sólo token.\n",
        "\n",
        "Acontinuación vamos a descargar los modelos para los idiomas Español e Inglés."
      ],
      "metadata": {
        "id": "iRSUG_sRn9TM"
      },
      "id": "iRSUG_sRn9TM"
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "kM8rDUIYbIcT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96faa8c6-421c-4a39-a338-2d0e9fbc9853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.23.5)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "id": "kM8rDUIYbIcT"
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "eng_spacy = spacy.load(\"en_core_web_sm\") # Cargue el modelo en inglés para tokenizar el texto en inglés\n",
        "def engTokenize(text):\n",
        "    \"\"\"\n",
        "    Tokeniza un texto en inglés y devuelve una lista de tokens\n",
        "    \"\"\"\n",
        "    return [token.text for token in eng_spacy.tokenizer(text)]\n"
      ],
      "metadata": {
        "id": "UuQ5R6C5kQUb"
      },
      "execution_count": null,
      "outputs": [],
      "id": "UuQ5R6C5kQUb"
    },
    {
      "cell_type": "code",
      "source": [
        "[engTokenize(x) for x in train_data[1][:6]]"
      ],
      "metadata": {
        "id": "A_53fkWgllA0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01996cff-0658-43cf-f772-058e890aa38e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['A',\n",
              "  'person',\n",
              "  'is',\n",
              "  'training',\n",
              "  'his',\n",
              "  'horse',\n",
              "  'for',\n",
              "  'a',\n",
              "  'competition',\n",
              "  '.'],\n",
              " ['A',\n",
              "  'person',\n",
              "  'is',\n",
              "  'at',\n",
              "  'a',\n",
              "  'diner',\n",
              "  ',',\n",
              "  'ordering',\n",
              "  'an',\n",
              "  'omelette',\n",
              "  '.'],\n",
              " ['A', 'person', 'is', 'outdoors', ',', 'on', 'a', 'horse', '.'],\n",
              " ['They', 'are', 'smiling', 'at', 'their', 'parents'],\n",
              " ['There', 'are', 'children', 'present'],\n",
              " ['The', 'kids', 'are', 'frowning']]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "id": "A_53fkWgllA0"
    },
    {
      "cell_type": "code",
      "source": [
        "engTokenize(\"AFK is an abbreviation for 'away from keyboard'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_1KWEx7YV2-",
        "outputId": "c92515fb-5c09-4a6f-ed01-caa8429d183b"
      },
      "id": "S_1KWEx7YV2-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AFK',\n",
              " 'is',\n",
              " 'an',\n",
              " 'abbreviation',\n",
              " 'for',\n",
              " \"'\",\n",
              " 'away',\n",
              " 'from',\n",
              " 'keyboard',\n",
              " \"'\",\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creación del Vocabulario"
      ],
      "metadata": {
        "id": "itxSyNyhAQBq"
      },
      "id": "itxSyNyhAQBq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estos tokens siguen siendo cadenas. Sin embargo, las entradas a nuestros modelos deben consistir en última instancia en entradas numéricas. A continuación, presentamos una clase para construir **`vocabularios`**, es decir, objetos que asocian cada valor de token distinto con un índice único. Primero, determinamos el conjunto de tokens únicos en nuestro corpus de entrenamiento. Luego asignamos un índice numérico a cada token único. Los elementos raros del vocabulario a menudo se eliminan por conveniencia. Cada vez que nos encontramos con un token en el tiempo de entrenamiento o prueba que no se había visto previamente o se había eliminado del vocabulario, la representamos por un token especial **`“<unk>”`**, lo que significa que este es un valor desconocido."
      ],
      "metadata": {
        "id": "1rX-t1OB-mDC"
      },
      "id": "1rX-t1OB-mDC"
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "class Vocab:\n",
        "    \"\"\"Vocabulario para texto.\"\"\"\n",
        "    def __init__(self, tokens=[], min_freq=0, reserved_tokens=[]):\n",
        "        \"\"\"Inicializa el vocabulario.\"\"\"\n",
        "        # Aplana una lista 2D si es necesario\n",
        "        if tokens and isinstance(tokens[0], list):\n",
        "            tokens = [token for line in tokens for token in line]\n",
        "        # Cuenta las frecuencias de los tokens\n",
        "        counter = collections.Counter(tokens)\n",
        "        self.token_freqs = sorted(counter.items(), key=lambda x: x[1],\n",
        "                                  reverse=True)\n",
        "        # La lista de tokens únicos\n",
        "        self.idx_to_token = list(sorted(set(['<unk>'] + reserved_tokens + [\n",
        "            token for token, freq in self.token_freqs if freq >= min_freq])))\n",
        "        # Mapea cada token a su índice\n",
        "        self.token_to_idx = {token: idx\n",
        "                             for idx, token in enumerate(self.idx_to_token)}\n",
        "\n",
        "    def __len__(self):\n",
        "        # Retorna el tamaño del vocabulario\n",
        "        return len(self.idx_to_token)\n",
        "\n",
        "    def __getitem__(self, tokens):\n",
        "        # Retorna el índice de un token o una lista de índices para varios tokens\n",
        "        if not isinstance(tokens, (list, tuple)):\n",
        "            return self.token_to_idx.get(tokens, self.unk)\n",
        "        return [self.__getitem__(token) for token in tokens]\n",
        "\n",
        "    def to_tokens(self, indices):\n",
        "        # Convierte un índice o una lista de índices en sus tokens correspondientes\n",
        "        if hasattr(indices, '__len__') and len(indices) > 1:\n",
        "            return [self.idx_to_token[int(index)] for index in indices]\n",
        "        return self.idx_to_token[indices]\n",
        "\n",
        "    @property\n",
        "    def unk(self):  # Índice para el token desconocido\n",
        "        return self.token_to_idx['<unk>']\n"
      ],
      "metadata": {
        "id": "Uhht9Xp07ssH"
      },
      "id": "Uhht9Xp07ssH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ffd5b6b9",
      "metadata": {
        "origin_pos": 9,
        "id": "ffd5b6b9"
      },
      "source": [
        "\n",
        "### Definición de una clase para cargar el conjunto de datos\n",
        "\n",
        "A continuación definimos una clase para cargar el conjunto de datos SNLI heredando de la clase `Dataset`. El argumento `num_steps` en el constructor de clases especifica la longitud de una secuencia de texto para que cada minilote de secuencias tenga la misma forma.\n",
        "En otras palabras, los tokens después de los primeros `num_steps` en una secuencia más larga se recortan, mientras que los tokens especiales “&lt;pad&gt;” se agregarán a secuencias más cortas hasta que su longitud se convierta en \"num_steps\".\n",
        "Al implementar la función `__getitem__`, podemos acceder arbitrariamente a la premisa, hipótesis y etiqueta con el índice `idx`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a7d4275",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-13T08:04:45.647261Z",
          "iopub.status.busy": "2022-07-13T08:04:45.646282Z",
          "iopub.status.idle": "2022-07-13T08:04:45.655841Z",
          "shell.execute_reply": "2022-07-13T08:04:45.654711Z"
        },
        "origin_pos": 11,
        "tab": [
          "pytorch"
        ],
        "id": "9a7d4275"
      },
      "outputs": [],
      "source": [
        "class SNLIDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"Un dataset personalizado para cargar el conjunto de datos SNLI.\"\"\"\n",
        "\n",
        "    def __init__(self, dataset, num_steps, tokenizer_function, vocab=None):\n",
        "        \"\"\"Inicializa el dataset con el conjunto de datos SNLI.\"\"\"\n",
        "        self.num_steps = num_steps\n",
        "        all_premise_tokens = [tokenizer_function(x) for x in dataset[0]]\n",
        "        all_hypothesis_tokens = [tokenizer_function(x) for x in dataset[1]]\n",
        "        if vocab is None:\n",
        "            self.vocab = Vocab(all_premise_tokens + all_hypothesis_tokens,\n",
        "                               min_freq=1, reserved_tokens=['<pad>'])\n",
        "        else:\n",
        "            self.vocab = vocab\n",
        "        self.premises = self._pad(all_premise_tokens)\n",
        "        self.hypotheses = self._pad(all_hypothesis_tokens)\n",
        "        self.labels = torch.tensor(dataset[2])\n",
        "        print('Se leyeron ' + str(len(self.premises)) + ' ejemplos')\n",
        "\n",
        "    def _pad(self, lines):\n",
        "        \"\"\"Realiza el padding o truncado de las secuencias a una longitud fija.\"\"\"\n",
        "        def truncate_pad(line, num_steps, padding_token):\n",
        "            if len(line) > num_steps:\n",
        "                return line[:num_steps]\n",
        "            return line + [padding_token] * (num_steps - len(line))\n",
        "\n",
        "        return torch.tensor([\n",
        "            truncate_pad(self.vocab[line], self.num_steps, self.vocab['<pad>'])\n",
        "            for line in lines])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Retorna un ejemplo en el índice dado.\"\"\"\n",
        "        return (self.premises[idx], self.hypotheses[idx]), self.labels[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Retorna el número de ejemplos en el dataset.\"\"\"\n",
        "        return len(self.premises)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e85c9c8",
      "metadata": {
        "origin_pos": 12,
        "id": "2e85c9c8"
      },
      "source": [
        "### Juntando todo\n",
        "\n",
        "Ahora podemos invocar la función `read_snli` y la clase `SNLIDataset` para descargar el conjunto de datos SNLI y devolver instancias de `DataLoader` para los conjuntos de entrenamiento y prueba, junto con el vocabulario del conjunto de entrenamiento.\n",
        "Es de destacar que debemos utilizar el vocabulario construido a partir del conjunto de entrenamiento como el del conjunto de prueba.\n",
        "Como resultado, cualquier token nuevo del conjunto de prueba será desconocido para el modelo entrenado en el conjunto de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9fc310d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-13T08:04:45.659754Z",
          "iopub.status.busy": "2022-07-13T08:04:45.659137Z",
          "iopub.status.idle": "2022-07-13T08:04:45.665370Z",
          "shell.execute_reply": "2022-07-13T08:04:45.664493Z"
        },
        "origin_pos": 14,
        "tab": [
          "pytorch"
        ],
        "id": "a9fc310d"
      },
      "outputs": [],
      "source": [
        "def load_data_snli(batch_size, tokenizer_function, num_steps=50):\n",
        "    \"\"\"Download the SNLI dataset and return data iterators and vocabulary.\"\"\"\n",
        "    num_workers = 2\n",
        "    data_dir = d2l.download_extract('SNLI')\n",
        "    train_data = read_snli(data_dir, True)\n",
        "    test_data = read_snli(data_dir, False)\n",
        "    train_set = SNLIDataset(train_data, num_steps, tokenizer_function)\n",
        "    test_set = SNLIDataset(test_data, num_steps, tokenizer_function, train_set.vocab)\n",
        "    train_iter = torch.utils.data.DataLoader(train_set, batch_size,\n",
        "                                             shuffle=True,\n",
        "                                             num_workers=num_workers)\n",
        "    test_iter = torch.utils.data.DataLoader(test_set, batch_size,\n",
        "                                            shuffle=False,\n",
        "                                            num_workers=num_workers)\n",
        "    return train_iter, test_iter, train_set.vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88d31087",
      "metadata": {
        "origin_pos": 15,
        "id": "88d31087"
      },
      "source": [
        "Aquí configuramos el tamaño del lote en 128 y la longitud de la secuencia en 50, e invocamos la función `load_data_snli` para obtener los iteradores de datos y el vocabulario. Luego imprimimos el tamaño del vocabulario.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b798e0a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-13T08:04:45.668928Z",
          "iopub.status.busy": "2022-07-13T08:04:45.668626Z",
          "iopub.status.idle": "2022-07-13T08:05:32.510783Z",
          "shell.execute_reply": "2022-07-13T08:05:32.509915Z"
        },
        "origin_pos": 16,
        "tab": [
          "pytorch"
        ],
        "id": "7b798e0a",
        "outputId": "71962932-fad3-43e2-a4cf-197bbc1a1880",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se leyeron 549367 ejemplos\n",
            "Se leyeron 9824 ejemplos\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39342"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "eng_spacy = spacy.load(\"en_core_web_sm\")\n",
        "def engTokenize(text): return [token.text for token in eng_spacy.tokenizer(text)]\n",
        "train_iter, test_iter, vocab = load_data_snli(128, engTokenize, 50)\n",
        "len(vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d9e5f5f",
      "metadata": {
        "origin_pos": 17,
        "id": "5d9e5f5f"
      },
      "source": [
        "Ahora imprimimos la forma del primer minibatch. Tenemos dos entradas `X[0]` y `X[1]` que representan pares de premisas e hipótesis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0196999c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-13T08:05:32.514671Z",
          "iopub.status.busy": "2022-07-13T08:05:32.514105Z",
          "iopub.status.idle": "2022-07-13T08:05:32.896162Z",
          "shell.execute_reply": "2022-07-13T08:05:32.894745Z"
        },
        "origin_pos": 18,
        "tab": [
          "pytorch"
        ],
        "id": "0196999c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d346d27-bb33-4e4e-ed29-416d7fba4df8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 50])\n",
            "torch.Size([128, 50])\n",
            "torch.Size([128])\n"
          ]
        }
      ],
      "source": [
        "for X, Y in train_iter:\n",
        "    print(X[0].shape)\n",
        "    print(X[1].shape)\n",
        "    print(Y.shape)\n",
        "    break"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}