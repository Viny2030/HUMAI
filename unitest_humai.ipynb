{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Viny2030/HUMAI/blob/main/unitest_humai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p project\n",
        "!touch project/__init__.py"
      ],
      "metadata": {
        "id": "9W5rWy1EpLNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tests unitarios\n",
        "\n",
        "Los tests unitarios (o unit tests) son la forma más común de tests. En pocas palabras, estos actúan sobre las partes más pequeñas y testables de una aplicación para asegurarse de que esa funcionalidad en particular funciona correctamente. Esto implica recorrer las partes más pequeñas e individuales del código. Idealmente, se realiza una prueba unitaria para cada parte del código en la aplicación, de forma aislada. Las pruebas unitarias son únicas en que son:\n",
        "\n",
        "Muy rápidas: en milisegundos o incluso más rápidas.\n",
        "Aisladas de dependencias lentas y/o propensas a errores (llamados a la DB o a APIs, etc)\n",
        "Deterministas: Si bien nos gustaría que todas las pruebas fueran deterministas, lograrlo para pruebas de integración o de end to end, es difícil en la práctica. Este criterio es de vital importancia para las pruebas unitarias.\n"
      ],
      "metadata": {
        "id": "_edMIgu3bO54"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modulo python unittest\n",
        "\n",
        "El módulo unittest es un framework de pruebas unitarias integrado en Python. Proporciona una serie de clases y métodos que permiten escribir y ejecutar pruebas unitarias de manera eficiente y organizada. Este está inspirado en otros frameworks de testeo unitario, como JUnit en Java. Permite a los desarrolladores crear casos de prueba, agruparlos en suites de pruebas y ejecutarlos de manera automatizada."
      ],
      "metadata": {
        "id": "aXZ6NO9wbJlR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GybtGhABa21b"
      },
      "outputs": [],
      "source": [
        "# %%writefile project/person.py\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class Person:\n",
        "    name: str\n",
        "    surname: str\n",
        "    title: str\n",
        "\n",
        "    def set_name(self, user_name):\n",
        "        self.name = user_name\n",
        "        return self.name\n",
        "\n",
        "    def get_name(self):\n",
        "        if not self.name and not self.surname:\n",
        "            raise Exception('Esta persona no tiene nombre')\n",
        "        else:\n",
        "            return f\"{self.surname}, {self.name}\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile project/test_person.py\n",
        "# from .person import Person\n",
        "import unittest\n",
        "import sys\n",
        "\n",
        "class TestPerson(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        print(\"Preparando la prueba\")\n",
        "        self.test_person = Person(\"Nachito\", \"Villaluenga\", \"Ingeniero de Software\")\n",
        "\n",
        "    def tearDown(self):\n",
        "        print(\"terminando la prueba\")\n",
        "        del self.test_person\n",
        "\n",
        "    def test_set_name(self):\n",
        "        # Arrange\n",
        "        print(\"Testeando test_set_name\")\n",
        "        persona = self.test_person\n",
        "        nombre_esperado = \"Jose Ignacio\"\n",
        "\n",
        "        # Act\n",
        "        nombre_obtenido = persona.set_name(nombre_esperado)\n",
        "\n",
        "        # Assert\n",
        "        self.assertEqual(nombre_esperado, nombre_obtenido, \"Los nombres no son iguales\")\n",
        "\n",
        "    def test_get_name(self):\n",
        "        # Arrange\n",
        "        print(\"Testeando test_get_name\")\n",
        "        persona = self.test_person\n",
        "        nombre_esperado = \"Villaluenga, Nachito\"\n",
        "\n",
        "        # Act\n",
        "        nombre_obtenido = persona.get_name()\n",
        "\n",
        "        # Assert\n",
        "        self.assertEqual(nombre_esperado, nombre_obtenido, \"Los nombres no son iguales\")\n",
        "\n",
        "    @unittest.skip(\"Salteamos este test\")\n",
        "    def test_nothing(self):\n",
        "        self.fail(\"Nunca va a llegar aca porque skipeamos\")\n",
        "\n",
        "    @unittest.skipIf(not sys.platform.startswith(\"win\"),\n",
        "                     \"Solo testeamos en windows\")\n",
        "    def test_format(self):\n",
        "        # Tests that work for only a certain version of the library.\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "ZO-kgnO9cF3j"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unittest.main(argv=[''], verbosity=2, exit=False)"
      ],
      "metadata": {
        "id": "F64bTP_bga5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d571813-92f8-412f-8848-580e96fd72c5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test_format (__main__.TestPerson) ... skipped 'Solo testeamos en windows'\n",
            "test_get_name (__main__.TestPerson) ... ok\n",
            "test_nothing (__main__.TestPerson) ... skipped 'Salteamos este test'\n",
            "test_set_name (__main__.TestPerson) ... ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 4 tests in 0.019s\n",
            "\n",
            "OK (skipped=2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparando la prueba\n",
            "Testeando test_get_name\n",
            "terminando la prueba\n",
            "Preparando la prueba\n",
            "Testeando test_set_name\n",
            "terminando la prueba\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.main.TestProgram at 0x7faf8409a4a0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Arrange-Act-Assert Pattern\n",
        "\n",
        "es una excelente manera de estructurar casos de prueba. Prescribe un orden de operaciones:\n",
        "\n",
        "1. Arrange: organiza las entradas y los objetivos, aqui se debe configurar el caso de prueba. ¿Requiere el test algún objeto o configuración especial? ¿Es necesario preparar una base de datos? ¿Es necesario iniciar sesión en una aplicación web? Realizamos todas estas operaciones aqui al principio de los tests.\n",
        "\n",
        "2. Act: Actuaa sobre el comportamiento que queremos probar, los pasos para cubrir lo que se va a probar. Esto podría ser llamar a una función o método, llamar a una API REST o interactuar con una página web, debemos mantener las acciones enfocadas en el comportamiento que queremos probar.\n",
        "\n",
        "3. Assert, probamos los resultados esperados, aqui debemos generar algún tipo de respuesta. Los pasos del assert verifican si esa respuesta es buena o mala, a veces, las afirmaciones son tan simples como verificar valores numéricos o de una lista, otras veces, pueden requerir verificar múltiples aspectos del sistema. Los asserts finalmente determinarán si el test aprueba o falla."
      ],
      "metadata": {
        "id": "0URj-7bSdrSg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modulo python pytest\n",
        "\n",
        "Pytest es un framework de testeo de Python que se originó a partir del proyecto PyPy. Se puede usar para escribir varios tipos de pruebas de software, incluidas pruebas unitarias, pruebas de integración, pruebas de extremo a extremo y mas."
      ],
      "metadata": {
        "id": "3dpjzDWrmRG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytest pytest-cov"
      ],
      "metadata": {
        "id": "aM_OXd8Kr86W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dc0a26b-b1af-430c-c4c5-3cefb46f24f4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (8.3.4)\n",
            "Collecting pytest-cov\n",
            "  Downloading pytest_cov-6.0.0-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest) (1.2.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest) (24.2)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest) (1.5.0)\n",
            "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from pytest) (2.2.1)\n",
            "Collecting coverage>=7.5 (from coverage[toml]>=7.5->pytest-cov)\n",
            "  Downloading coverage-7.6.10-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\n",
            "Downloading pytest_cov-6.0.0-py3-none-any.whl (22 kB)\n",
            "Downloading coverage-7.6.10-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: coverage, pytest-cov\n",
            "Successfully installed coverage-7.6.10 pytest-cov-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile project/test_person.py\n",
        "# from .person import Person\n",
        "import pytest\n",
        "import sys\n",
        "\n",
        "@pytest.fixture\n",
        "def get_person():\n",
        "    print(\"Preparando la prueba\")\n",
        "    yield Person(\"Nachito\", \"Villaluenga\", \"Ingeniero de Software\")\n",
        "    print(\"terminando la prueba\")\n",
        "\n",
        "\n",
        "def test_set_name(get_person):\n",
        "    # Arrange\n",
        "    print(\"Testeando test_set_name\")\n",
        "    nombre_esperado = \"Jose Ignacio\"\n",
        "\n",
        "    # Act\n",
        "    nombre_obtenido = get_person.set_name(nombre_esperado)\n",
        "\n",
        "    # Assert\n",
        "    assert nombre_esperado == nombre_obtenido, \"Los nombres no son iguales\"\n",
        "\n",
        "def test_get_name(get_person):\n",
        "    # Arrange\n",
        "    print(\"Testeando test_get_name\")\n",
        "    nombre_esperado = \"Villaluenga, Nachito\"\n",
        "\n",
        "    # Act\n",
        "    nombre_obtenido = get_person.get_name()\n",
        "\n",
        "    # Assert\n",
        "    assert nombre_esperado == nombre_obtenido, \"Los nombres no son iguales\"\n",
        "\n",
        "@pytest.mark.skip(\"Salteamos este test\")\n",
        "def test_nothing():\n",
        "    raise Exception(\"Nunca va a llegar aca porque skipeamo\")\n",
        "\n",
        "@pytest.mark.skipIf(not sys.platform.startswith(\"win\"),\n",
        "                    \"Solo testeamos en windows\")\n",
        "def test_format():\n",
        "    # Tests that work for only a certain version of the library.\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "LOITBdOfv_38"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pytest --cov project/"
      ],
      "metadata": {
        "id": "mPwSU3A9pHNv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83c000f9-7332-412e-c72e-08cd5cc7ec19"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-8.3.4, pluggy-1.5.0\n",
            "rootdir: /content\n",
            "plugins: cov-6.0.0, anyio-3.7.1, typeguard-4.4.1\n",
            "\u001b[1mcollecting ... \u001b[0m\u001b[1m\rcollected 0 items                                                                                  \u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/coverage/inorout.py:508: CoverageWarning: Module project/ was never imported. (module-not-imported)\n",
            "  self.warn(f\"Module {pkg} was never imported.\", slug=\"module-not-imported\")\n",
            "/usr/local/lib/python3.10/dist-packages/coverage/control.py:892: CoverageWarning: No data was collected. (no-data-collected)\n",
            "  self._warn(\"No data was collected.\", slug=\"no-data-collected\")\n",
            "\u001b[31m\u001b[1m\n",
            "WARNING: Failed to generate report: No data to report.\n",
            "\n",
            "\u001b[0m/usr/local/lib/python3.10/dist-packages/pytest_cov/plugin.py:341: CovReportWarning: Failed to generate report: No data to report.\n",
            "\n",
            "  warnings.warn(CovReportWarning(message), stacklevel=1)\n",
            "\n",
            "\n",
            "---------- coverage: platform linux, python 3.10.12-final-0 ----------\n",
            "\n",
            "\u001b[33m====================================== \u001b[33mno tests ran\u001b[0m\u001b[33m in 0.02s\u001b[0m\u001b[33m =======================================\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pytest --cov --cov-report=html:coverage_re\n",
        "!tar -cvf coverage.tar coverage_re"
      ],
      "metadata": {
        "id": "1RN2hqUNstIN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90f56e6b-fcc4-4245-883b-c8cab60c8bf2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-8.3.4, pluggy-1.5.0\n",
            "rootdir: /content\n",
            "plugins: cov-6.0.0, anyio-3.7.1, typeguard-4.4.1\n",
            "\u001b[1mcollecting ... \u001b[0m\u001b[1m\rcollected 0 items                                                                                  \u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/coverage/control.py:892: CoverageWarning: No data was collected. (no-data-collected)\n",
            "  self._warn(\"No data was collected.\", slug=\"no-data-collected\")\n",
            "\u001b[31m\u001b[1m\n",
            "WARNING: Failed to generate report: No data to report.\n",
            "\n",
            "\u001b[0m/usr/local/lib/python3.10/dist-packages/pytest_cov/plugin.py:341: CovReportWarning: Failed to generate report: No data to report.\n",
            "\n",
            "  warnings.warn(CovReportWarning(message), stacklevel=1)\n",
            "\n",
            "\n",
            "---------- coverage: platform linux, python 3.10.12-final-0 ----------\n",
            "\n",
            "\u001b[33m====================================== \u001b[33mno tests ran\u001b[0m\u001b[33m in 0.02s\u001b[0m\u001b[33m =======================================\u001b[0m\n",
            "tar: coverage_re: Cannot stat: No such file or directory\n",
            "tar: Exiting with failure status due to previous errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile project/person_functions.py\n",
        "# from .person import Person\n",
        "import requests\n",
        "\n",
        "def create_person_with_input():\n",
        "    name = input(\"Escribre el nombre de la persona: \")\n",
        "    surname = input(\"Escribre el apellido de la persona: \")\n",
        "    title = input(\"Escribre el titulo de la persona: \")\n",
        "    return Person(name, surname, title)\n",
        "\n",
        "def tell_a_joke(person: Person):\n",
        "    result = requests.get(\"https://v2.jokeapi.dev/joke/Programming?lang=es&type=single\")\n",
        "    json = result.json()\n",
        "    if json[\"type\"] == \"single\":\n",
        "        joke = json[\"joke\"]\n",
        "    else:\n",
        "        joke = f'{json[\"setup\"]}\\n{json[\"delivery\"]}'\n",
        "    print(f\"{person.get_name()} dice una broma:\")\n",
        "    print(joke)"
      ],
      "metadata": {
        "id": "XLyAitR1e2FY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "person = create_person_with_input()\n",
        "tell_a_joke(person)"
      ],
      "metadata": {
        "id": "LAo5U9OL32jV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fe3197d-89b7-43a3-959e-185da1b40282"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Escribre el nombre de la persona: vicente monteverde\n",
            "Escribre el apellido de la persona: monteverde\n",
            "Escribre el titulo de la persona: phd\n",
            "monteverde, vicente monteverde dice una broma:\n",
            "Sólo hay 10 tipos de personas en este mundo, las que entienden binario y las que no.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile project/test_person_functions.py\n",
        "# from .person_functions import create_person_with_input, tell_a_joke\n",
        "# from .person import Person\n",
        "from pytest import MonkeyPatch\n",
        "import pytest\n",
        "import sys\n",
        "import requests\n",
        "\n",
        "def test_create_person_with_input(monkeypatch: MonkeyPatch):\n",
        "    # Arrange\n",
        "    inputs = [\"Jose Ignacio\", \"Villaluenga\", \"Ingeniero de software\"]\n",
        "    monkeypatch.setattr(\"builtins.input\", lambda _: inputs.pop(0))\n",
        "    nombre = \"Jose Ignacio\"\n",
        "    apellido = \"Villaluenga\"\n",
        "    titulo = \"Ingeniero de software\"\n",
        "\n",
        "    # Act\n",
        "    persona_obtenida = create_person_with_input()\n",
        "\n",
        "    # Assert\n",
        "    assert nombre == persona_obtenida.name\n",
        "    assert apellido == persona_obtenida.surname\n",
        "    assert titulo == persona_obtenida.title\n",
        "\n",
        "class MockResponse:\n",
        "    def __init__(self, json):\n",
        "        self.json_data = json\n",
        "\n",
        "    def json(self):\n",
        "        return self.json_data\n",
        "\n",
        "def test_tell_a_joke():\n",
        "    # Arrange\n",
        "    mock_response = MockClient({\"type\": \"single\", \"joke\": \"mock jock\"})\n",
        "    monkeypatch.setattr(requests, \"get\", lambda _: mock_response)\n",
        "\n",
        "    # Act\n",
        "    tell_a_joke(Person(\"Nombre\", \"Apelldio\", \"titulo\"), mock_response)\n",
        "\n",
        "    # Assert\n",
        "\n",
        "def test_tell_a_joke_fail(monkeypatch: MonkeyPatch):\n",
        "    # Arrange\n",
        "    mock_response = MockResponse({\"type\": \"fail\", \"joke\": \"mock jock\"})\n",
        "    monkeypatch.setattr(requests, \"get\", lambda _: mock_response)\n",
        "\n",
        "    # Act and assert\n",
        "    with pytest.raises(KeyError):\n",
        "        tell_a_joke(Person(\"Nombre\", \"Apelldio\", \"titulo\"))\n"
      ],
      "metadata": {
        "id": "s_KmCz2F4gfT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pytest --cov project/"
      ],
      "metadata": {
        "id": "FIMpAXG__GnZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1464a998-ed7b-4c1b-f4bb-a3466d3a51fc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-8.3.4, pluggy-1.5.0\n",
            "rootdir: /content\n",
            "plugins: cov-6.0.0, anyio-3.7.1, typeguard-4.4.1\n",
            "\u001b[1mcollecting ... \u001b[0m\u001b[1m\rcollected 0 items                                                                                  \u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/coverage/inorout.py:508: CoverageWarning: Module project/ was never imported. (module-not-imported)\n",
            "  self.warn(f\"Module {pkg} was never imported.\", slug=\"module-not-imported\")\n",
            "/usr/local/lib/python3.10/dist-packages/coverage/control.py:892: CoverageWarning: No data was collected. (no-data-collected)\n",
            "  self._warn(\"No data was collected.\", slug=\"no-data-collected\")\n",
            "\u001b[31m\u001b[1m\n",
            "WARNING: Failed to generate report: No data to report.\n",
            "\n",
            "\u001b[0m/usr/local/lib/python3.10/dist-packages/pytest_cov/plugin.py:341: CovReportWarning: Failed to generate report: No data to report.\n",
            "\n",
            "  warnings.warn(CovReportWarning(message), stacklevel=1)\n",
            "\n",
            "\n",
            "---------- coverage: platform linux, python 3.10.12-final-0 ----------\n",
            "\n",
            "\u001b[33m====================================== \u001b[33mno tests ran\u001b[0m\u001b[33m in 0.04s\u001b[0m\u001b[33m =======================================\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zA0jctJA_K_T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}